# -*- coding: utf-8 -*-
"""Consolidado6_finalfinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kLj1W7NgNB_HgBu5GbY7GgnjAElaRJ2H
"""

#INSTRUCCIONES
#1. Carga y exploración de datos
#Carga el dataset proporcionado, que contiene información sobre temperatura media, cambio en las precipitaciones, frecuencia de sequías y producción agrícola en distintos países.
import pandas as pd
import numpy as np

#Carga de dataset desde GitHub
url = "https://raw.githubusercontent.com/Aconstanza/Portafolio/refs/heads/main/cambio_climatico_agricultura.csv"
df = pd.read_csv(url)
print(df)

#Inspección inicial
print("Información del dataset:")
print(df.info(), "\n")
print("----------------------")
#Limpieza de datos
print("Valores faltantes por columna: ")
print(df.isnull().sum(), "\n")
print("----------------------")
df_cleaned = df.dropna()
print(df_cleaned)
print("----------------------")
print("Duplicados en el dataset: ")
print(df.duplicated().sum(), "\n")
df_cleaned = df_cleaned.drop_duplicates()
print(df_cleaned)

#Analiza la distribución de las variables y detecta posibles valores atípicos o tendencias.
##Importación de librerías para analisis de distribución de las variables
import matplotlib.pyplot as plt
import seaborn as sns
sns.pairplot(df_cleaned[['Temperatura_promedio','Cambio_lluvias','Frecuencia_sequías', 'Producción_alimentos', 'País']], hue='País',diag_kind='kde')
plt.suptitle('Matriz entre temperatura, cambios de lluvia, frecuencia de sequías, Producción alimentaria por País ', y=1.02)

plt.show()

g=sns.PairGrid(df_cleaned, vars=['Temperatura_promedio','Cambio_lluvias','Frecuencia_sequías', 'Producción_alimentos'], hue="País")

g.map_diag(sns.kdeplot)
g.map_offdiag(sns.regplot)
g.add_legend(title="País")
plt.suptitle("pairGrid personalizado de temperatura, cambios de lluvia, frecuencia de sequías, Producción alimentaria", y=1.02)

plt.show()

#Grafico para ver la producción promedio por país
produccion_promedio = df_cleaned.groupby('País')['Producción_alimentos'].mean().sort_values()

plt.figure(figsize=(10, 6))
sns.barplot(x=produccion_promedio.values, y=produccion_promedio.index, palette='viridis')
plt.title('Producción de alimentos promedio por país')
plt.xlabel('Producción promedio')
plt.ylabel('País')
plt.tight_layout()
plt.show()

# Calcular la matriz de correlación
correlation_matrix = df_cleaned[['Temperatura_promedio', 'Cambio_lluvias', 'Frecuencia_sequías', 'Producción_alimentos']].corr()

# Crear un mapa de calor con seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Mapa de Calor de las Correlaciones entre Variables')
plt.tight_layout()
plt.show()

for col in ['Temperatura_promedio', 'Cambio_lluvias', 'Frecuencia_sequías', 'Producción_alimentos']:
    plt.figure()
    sns.boxplot(y=df_cleaned[col])
    plt.title(f'Boxplot de {col}')
    plt.show()


#2. Preprocesamiento y escalamiento de datos (2 puntos)
#• Aplica técnicas de normalización o estandarización a las variables numéricas.
#• Codifica correctamente cualquier variable categórica si fuera necesario.

from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder, StandardScaler

#OneHotEncoding
df_encoded = pd.get_dummies(df_cleaned, columns=['País'], drop_first=True)
print(df_encoded)

#ESTANDARIZACION MINMAX SCALER
scaler = MinMaxScaler()
df_scaled_mms = df_encoded.copy()
df_scaled_mms[df_cleaned.drop(columns=["País"]).columns] = scaler.fit_transform(
    df_cleaned.drop(columns=["País"])
)
print(df_scaled_mms)

#ESTANDARIZACION STANDARD SCALER
scaler = StandardScaler()
df_scaled_ss = scaler.fit_transform(df_encoded)
print(df_scaled_ss)

#• Divide los datos en conjunto de entrenamiento y prueba (80%-20%).
from sklearn.model_selection import train_test_split

X = df_scaled_mms.drop(columns=["Producción_alimentos"])
y = df_scaled_mms["Producción_alimentos"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

##3. Aplicación de modelos de aprendizaje supervisado (4 puntos)
#•  Regresión:
#Entrena un modelo de regresión lineal para predecir la producción de alimentos.
from sklearn.linear_model import LinearRegression

modelo_lr = LinearRegression()

#fitting the model
modelo_lr.fit(X_train,y_train)
y_pred = modelo_lr.predict(X_test)

#Evalúa el modelo usando métricas como MAE, MSE y R2.
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score
intercepto = modelo_lr.intercept_
pendiente = modelo_lr.coef_[0]
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
MAE = mean_absolute_error(y_test, y_pred)

print("----------------------------")
print("Regresión Lineal")
print(f"Intercepto: {intercepto:.2f}")
print(f"Pendiente: {pendiente:.2f}")
print(f"Error Cuadrático Medio: {mse:.2f}")
print(f"Coeficiente de Determinación : {r2:.3f}")
print("MAE: ", MAE)

print('------------------------------')
#Compara con otros modelos de regresión (árbol de decisión, random forest).
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
tree_model = DecisionTreeRegressor(random_state=42)
tree_model.fit(X_train, y_train)
y_pred_tree = tree_model.predict(X_test)

# Evaluación
mse_tree = mean_squared_error(y_test, y_pred_tree)
mae_tree = mean_absolute_error(y_test, y_pred_tree)
r2_tree = r2_score(y_test, y_pred_tree)

print("Árbol de Decisión")
print(f"MSE: {mse_tree:.4f}")
print(f"MAE: {mae_tree:.4f}")
print(f"R²: {r2_tree:.4f}\n")

print('-----------------------')
from sklearn.ensemble import RandomForestRegressor
forest_model = RandomForestRegressor(n_estimators=100, random_state=42)
forest_model.fit(X_train, y_train)
# Predicción
y_pred_forest = forest_model.predict(X_test)

# Evaluación
mse_forest = mean_squared_error(y_test, y_pred_forest)
mae_forest = mean_absolute_error(y_test, y_pred_forest)
r2_forest = r2_score(y_test, y_pred_forest)

print("Random Forest")
print(f"MSE: {mse_forest:.4f}")
print(f"MAE: {mae_forest:.4f}")
print(f"R²: {r2_forest:.4f}")


def plot_regression_results(y_true, y_pred, title):
    plt.figure(figsize=(6, 6))
    sns.scatterplot(x=y_true, y=y_pred)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], '--r')  # Línea 45°
    plt.xlabel('Valor Real')
    plt.ylabel('Predicción del Modelo')
    plt.title(f'{title}\nReal vs Predicho')
    plt.legend(['Modelo', '45°'])
    plt.grid(True)
    plt.tight_layout()
    plt.show()

plot_regression_results(y_test, y_pred, "Regresión Lineal")
plot_regression_results(y_test, y_pred_tree, "Árbol de Decisión")
plot_regression_results(y_test, y_pred_forest, "Random Forest")

def plot_residuals(y_true, y_pred, title):
    residuals = y_true - y_pred
    plt.figure(figsize=(6, 4))
    sns.scatterplot(x=y_pred, y=residuals)
    plt.axhline(0, color='red', linestyle='--')
    plt.xlabel('Predicción')
    plt.ylabel('Error (Residual)')
    plt.title(f'Residuales: {title}')
    plt.grid(True)
    plt.tight_layout()
    plt.show()
plot_residuals(y_test, y_pred, "Regresión Lineal")

#####Clasificación:
print("Algoritmos de Clasificación")
#Crea una nueva variable categórica que clasifique los países en "Bajo", "Medio" y
#"Alto" impacto climático en la producción agrícola.

df_cleanedc = df_cleaned.copy()

def clasificar_impacto(valor):
    if valor < df_cleanedc["Producción_alimentos"].quantile(0.33):
        return "Bajo"
    elif valor < df_cleanedc["Producción_alimentos"].quantile(0.66):
        return "Medio"
    else:
        return "Alto"
# Crear nueva variable
df_cleanedc["Impacto_climático"] = df_cleanedc["Producción_alimentos"].apply(clasificar_impacto)

print(df_cleanedc[["Producción_alimentos", "Impacto_climático"]].head(10))

le = LabelEncoder()
df_cleanedc["Impacto_climático_encoded"] = le.fit_transform(df_cleanedc["Impacto_climático"])

X_class=df_cleanedc.drop(columns=["Producción_alimentos", "Impacto_climático", "Impacto_climático_encoded", "País"])
X_class = scaler.fit_transform(X_class)
y_class = df_cleanedc["Impacto_climático_encoded"]

Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)

# Entrena modelos de clasificación como K-Nearest Neighbors, Árbol de Decisión y Support Vector Machine.

print("------------------------")
print("K-Nearest Neighbors:")
from sklearn.neighbors import KNeighborsClassifier

modelo_knn = KNeighborsClassifier(n_neighbors=3)
modelo_knn.fit(Xc_train, yc_train)

y_pred_knn = modelo_knn.predict(Xc_test)

print("X_train escalado:", Xc_train)
print("X_test escalado:", Xc_test)

print("y_test:", yc_test)
print("y_pred_knn:", y_pred_knn)

print("Exactitud:", accuracy_score(yc_test, y_pred_knn))

print("------------------------")
#Arbol de decision
print("Árbol de decisión:")
from sklearn.tree import DecisionTreeClassifier

modelo_arbol= DecisionTreeClassifier(max_depth=3, random_state=42)
modelo_arbol.fit(Xc_train, yc_train)

y_pred_arbol = modelo_arbol.predict(Xc_test)

print("Exactitud:", accuracy_score(yc_test, y_pred_arbol))

print("---------------------------")
print("Support Vector Machine:")

from sklearn.svm import SVC
#SVM

modelo_svm = SVC(kernel='linear', C=1, probability=True)
modelo_svm.fit(Xc_train, yc_train)

y_pred_svm = modelo_svm.predict(Xc_test)
print("Exactitud:", accuracy_score(yc_test, y_pred_svm))

print("-----------------------------")
#Evalúa el desempeño usando matriz de confusión, precisión, sensibilidad y curva ROC-AUC.
print("Evaluación del desempeño")
print("Matriz de confusión:")
from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_curve, auc


#Matriz de Confusión

conf_matriz = confusion_matrix(yc_test, y_pred_knn)
print("Matriz de confusión:\n", conf_matriz)

precision = precision_score(yc_test, y_pred_knn, average='weighted')
print("Precisión:", precision)

sensibilidad = recall_score(yc_test, y_pred_knn, average='weighted')
espeficidad = recall_score(yc_test, y_pred_knn, pos_label=0)
print(f"Sensibilidad: {sensibilidad}")
print(f"Especificidad, {espeficidad}")

#roc curve
from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_score, recall_score
from sklearn.multiclass import OneVsRestClassifier
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Modelos de clasificación: K-Nearest Neighbors, Decision Tree and Support Vector Machine
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

# Modelo KNN
modelo_knn = KNeighborsClassifier(n_neighbors=3)
modelo_knn.fit(Xc_train, yc_train)

# Obtener probabilidades predichas
y_proba_knn = modelo_knn.predict_proba(Xc_test)

# Modelo Árbol de Decisión
modelo_arbol = DecisionTreeClassifier(max_depth=3, random_state=42, class_weight='balanced')
modelo_arbol.fit(Xc_train, yc_train)

# Obtener probabilidades predichas
y_proba_arbol = modelo_arbol.predict_proba(Xc_test)

# Modelo Support Vector Machine con probabilidad habilitada
modelo_svm = SVC(kernel='linear', C=1, probability=True, class_weight='balanced')
modelo_svm.fit(Xc_train, yc_train)

# Obtener probabilidades predichas
y_proba_svm = modelo_svm.predict_proba(Xc_test)

# Calculo y grafico curva ROC
def plot_roc_curve(y_true, y_prob, model_name, classes, ax=None):
    """Generates a ROC curve plot for each class."""
    if ax is None:
        ax = plt.gca()
    for i, c in enumerate(classes):
        fpr, tpr, _ = roc_curve(y_true == i, y_prob[:, i])
        roc_auc = auc(fpr, tpr)
        ax.plot(fpr, tpr, label=f'{c} (AUC = {roc_auc:.2f})')

    ax.plot([0, 1], [0, 1], color='gray', linestyle='--')
    ax.set_xlabel('False Positive Rate (FPR)')
    ax.set_ylabel('True Positive Rate (TPR)')
    ax.set_title(f'{model_name}: ROC Curve')
    ax.legend(loc='lower right')

# Plot ROC curve for KNN
plt.figure(figsize=(12, 8))
plt.subplot(1, 3, 1)
plot_roc_curve(yc_test, y_proba_knn, "KNN", le.classes_)

# Plot ROC curve for Decision Tree
plt.subplot(1, 3, 2)
plot_roc_curve(yc_test, y_proba_arbol, "Decision Tree", le.classes_)

# Plot ROC curve for SVM
plt.subplot(1, 3, 3)
plot_roc_curve(yc_test, y_proba_svm, "SVM", le.classes_)

plt.tight_layout()
plt.show()

#4. Optimización de modelos (2 puntos)
#• Ajusta hiperparámetros utilizando validación cruzada y búsqueda en grilla.
#• Aplica técnicas de regularización y analiza su impacto en los modelos.
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import make_regression
from sklearn.model_selection import GridSearchCV

X, y = make_regression(n_samples=100, n_features=10, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#RIDGE REGRESIÓN
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
y_pred_ridge = ridge.predict(X_test)
mse_ridge = mean_squared_error(y_test, y_pred_ridge)
r2_ridge = r2_score(y_test, y_pred_ridge)
print(f"Ridge Regresión: MSE: {mse_ridge:.4f}, R²: {r2_ridge:.4f}")

#LASSO REGRESIÓN
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
y_pred_lasso = lasso.predict(X_test)
mse_lasso = mean_squared_error(y_test, y_pred_lasso)
r2_lasso = r2_score(y_test, y_pred_lasso)
print(f"Lasso Regresión: MSE: {mse_lasso:.4f}, R²: {r2_lasso:.4f}")

#ELASTIC NET
elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)
elastic_net.fit(X_train, y_train)
y_pred_elastic = elastic_net.predict(X_test)
mse_elastic = mean_squared_error(y_test, y_pred_elastic)
r2_elastic = r2_score(y_test, y_pred_elastic)
print(f"Elastic Net Regresión: MSE: {mse_elastic:.4f}, R²: {r2_elastic:.4f}")


!pip install scikit-optimize

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from skopt import BayesSearchCV
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split


data = df_cleanedc.drop(columns=["Producción_alimentos", "Impacto_climático", "Impacto_climático_encoded", "País"])
data = scaler.fit_transform(data)

Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42) # Use X_class instead of X

modelo1 = RandomForestClassifier(random_state=42)
param_grid1 = {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10]}
grid_search1 = GridSearchCV(modelo1, param_grid1, cv=5, scoring="accuracy")
grid_search1.fit(Xc_train, yc_train)
print(f"Mejores parámetros para modelo 1:, {grid_search1.best_params_}")


param_dist = {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10]}
random_search = RandomizedSearchCV(modelo1, param_distributions=param_dist, n_iter=10, cv=5, scoring="accuracy")
random_search.fit(Xc_train, yc_train)
print(f"Mejores parámetros para modelo 1:, {random_search.best_params_}")

bayes_search = BayesSearchCV(modelo1, param_grid1, n_iter=10, cv=5, scoring="accuracy")
bayes_search.fit(Xc_train, yc_train)
print(f"Mejores parámetros para modelo 1:, {bayes_search.best_params_}")

#5. Análisis de resultados y conclusiones (1 punto)
#• Compara los modelos utilizados y justifica cuál ofrece mejores resultados para la predicción y clasificación.

#Los modelos no capturaron bien la relación entre las variables. Y los tres modelos obtuvieron un R^2 negativo, lo que indica que no están explicando bien la variabilidad de los datos.
#Esto se puede explicar porque el dataset es muy pequeño o que faltan más variables que expliquen la producción de alimentos.
#No obstante, Random Forest tiene una capacidad de generalización mejor y un ajuste más preciso de los datos, con menor MSE y mayor R^2.

#En cuanto a los algoritmos de clasificación, SVM mostró mayor exactitud con un 80%

#• Relaciona los hallazgos con posibles implicaciones en la seguridad alimentaria global

##Podemos observar que las variables climaticas están fuertemente interrelacionadas, la matriz de correlación nos da a entender que a mayor temperatura promedio
#disminuyen las lluvias(-0,81), y aumenta la frecuencia de sequías (0.83). Y es precisamente está última variable la que presenta mayor correlación (aunque negativa) con la producción de alimentos (-0.72).

#Esto indica que el cambio climático reduce la producción alimentaria mundial, y genera riesgos para la seguridad alimentaria.
#Y una de las variables que sería interesante analizar es la inversión en tecnología agrícola, practicas agricolas y política públicas destinadas a esta área. E incluso variables como el PH del suelo y los usos de fertilizantes.

#Y países con alto impacto climático podrían presnetar incremento en precios, interrupciones en la cadena de suministros. Y a nivel global, aumento en la desigualdad regional y migraciones.

#Como respuesta, se necesita cooperación internacional, inversión en tecnologia de adaptacion y resiliencia agrícola

