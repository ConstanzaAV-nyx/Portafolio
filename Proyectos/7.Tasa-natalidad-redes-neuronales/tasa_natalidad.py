# -*- coding: utf-8 -*-
"""consolidado_8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VmZz0G_zUnY6Z3Qq2qbePs_Hua4ciZJ-
"""

!pip install tensorflow scikit-learn

!pip install scikit-optimize

#INSTRUCCIONES

##Carga de librerías
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras import backend as K
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


#1. Carga y exploración de datos (1 punto)
url = "https://raw.githubusercontent.com/Aconstanza/Portafolio/refs/heads/main/dataset_natalidad.csv"
df = pd.read_csv(url)
#• Carga el dataset proporcionado, que contiene información de distintos países sobre: o PIB per cápita
#o Acceso a servicios de salud (% de la población)
#o Nivel educativo promedio
#o Tasa de empleo femenino
#o Edad promedio de maternidad
#o Índice de urbanización
#o Tasa de natalidad (variable objetivo)
print("Información del dataset:")
print(df.info(), "\n")
print("Valores faltantes por columna: ")
print(df.isnull().sum(), "\n")
print("Duplicados en el dataset: ")
print(df.duplicated().sum(), "\n")
print(df.describe())
df_cleaned = df.dropna()
print(df_cleaned)
df_cleaned = df_cleaned.drop_duplicates()
print(df_cleaned)

#• Analiza las correlaciones entre variables y visualiza su distribución.
sns.pairplot(df_cleaned.drop('País', axis=1))
plt.show()

#Matriz de correlación
corr_matrix = df_cleaned.drop('País', axis=1).corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Matriz de correlación')
plt.show()

plt.figure(figsize=(8, 6))
sns.histplot(df_cleaned['Tasa_Natalidad'], kde=True, bins=20)
plt.title("Distribución de la Tasa de Natalidad")
plt.xlabel("Tasa de Natalidad")
plt.ylabel("Frecuencia")
plt.show()

sns.boxplot(x=df_cleaned['PIB_per_capita'])
plt.show()


##PREPROCESAMIENTO
##División de los datos en conjunto de entrenamiento y prubea

X = df_cleaned.drop(['Tasa_Natalidad', 'País'], axis=1)
y = df_cleaned['Tasa_Natalidad']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


#Normalización de los datos
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#2. Diseño y entrenamiento del modelo (5 puntos)
modelo = Sequential()
#• Diseña una red neuronal con la siguiente estructura:

#Capa de entrada con tantas neuronas como variables predictoras.
modelo.add(Dense(units=128, activation='relu', input_dim=X_train_scaled.shape[1], kernel_regularizer=l2(0.01)))
modelo.add(Dropout(0.2))
#Mínimo de 2 capas ocultas con activaciones adecuadas.
modelo.add(Dense(units=64, activation='sigmoid'))
modelo.add(Dropout(0.2))

modelo.add(Dense(units=32, activation='relu'))

#Capa de salida con una neurona para predecir la tasa de natalidad.
modelo.add(Dense(units=1, activation='linear'))
#• Utiliza optimizadores adecuados y experimenta con diferentes valores de learning rate.
#• Aplica diferentes funciones de activación y evalúa su impacto.
#• Aplica regularización (dropout o L2) para evitar el sobreajuste.
#• Entrena el modelo utilizando una función de pérdida adecuada para problems de regresión.
# Experimento con diferentes valores de learning rate
modelo.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
def r2_metric(y_true, y_pred):
    ss_res = K.sum(K.square(y_true - y_pred))
    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))
    return (1 - ss_res / ss_tot)
#3. Evaluación y optimización del modelo (3 puntos)
#• Evalúa el modelo con datos de prueba.
learning_rates = [0.1, 0.01, 0.001, 0.0001]
for lr in learning_rates:
    optimizer = Adam(learning_rate=lr)
    modelo.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae', r2_metric])
    history = modelo.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)
    loss, mae, r2 = modelo.evaluate(X_test_scaled, y_test)
    print(f"Learning Rate: {lr} - Pérdida: {loss}, MAE: {mae}, R2: {r2}")

plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()
plt.show()


#• Ajusta hiperparámetros para mejorar el rendimiento.
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

#Creación del modelo
def create_model(learning_rate=0.001, units=64, dropout_rate=0.2):
    modelo = Sequential()
    modelo.add(Dense(units=units, activation='relu', input_dim=X_train_scaled.shape[1]))
    modelo.add(Dropout(dropout_rate))
    modelo.add(Dense(units=32, activation='relu'))
    modelo.add(Dense(units=1, activation='linear'))
    modelo.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])
    return modelo

# Búsqueda manual de hiperparámetros
learning_rates = [0.1, 0.01, 0.001]
neurons = [32, 64, 128]
batch_sizes = [16, 32]
dropout_rates = [0.2, 0.3]

#Registro del mejor modelo y su rendimiento
best_model = None
best_loss = float('inf')
best_params = {}

for lr in learning_rates:
    for units in neurons:
        for batch_size in batch_sizes:
            for dropout_rate in dropout_rates:
                print(f"Entrenando modelo con LR={lr}, Neurons={units}, Batch Size={batch_size}, Dropout={dropout_rate}")

                # Crear y entrenar el modelo
                model = create_model(learning_rate=lr, units=units, dropout_rate=dropout_rate)
                history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=batch_size, validation_data=(X_test_scaled, y_test), verbose=0)

                # Evaluar el modelo
                loss, mae = model.evaluate(X_test_scaled, y_test, verbose=0)

                # Verificar si este modelo es el mejor hasta ahora
                if loss < best_loss:
                    best_loss = loss
                    best_model = model
                    best_params = {'learning_rate': lr, 'neurons': units, 'batch_size': batch_size, 'dropout_rate': dropout_rate}

# Mostrar los mejores parámetros
print(f"Mejores parámetros: {best_params}")
print(f"Pérdida en el conjunto de prueba: {best_loss}")

#• Analiza el impacto de cada variable en la predicción.
# Extraer los pesos de la capa de entrada
weights = best_model.layers[0].get_weights()[0]
feature_importance = pd.DataFrame(np.abs(weights).sum(axis=1), index=X.columns, columns=["Importancia"])
feature_importance = feature_importance.sort_values(by="Importancia", ascending=False)

# Visualización de las características más importantes
sns.barplot(x=feature_importance["Importancia"], y=feature_importance.index)
plt.title("Importancia de las Características")
plt.xlabel("Importancia")
plt.ylabel("Características")
plt.show()


#• Realiza predicciones con el modelo y compáralas con datos reales.
y_pred = modelo.predict(X_test_scaled)

# Visualiza las predicciones vs los valores reales
plt.scatter(y_test, y_pred)
plt.xlabel("Valores Reales de Tasa de Natalidad")
plt.ylabel("Predicciones de Tasa de Natalidad")
plt.title("Predicciones vs Realidad")
plt.show()

# Cálculo del error
error = np.abs(y_test - y_pred.flatten())
print(f"Error absoluto medio (MAE): {np.mean(error)}")


#4. Análisis de resultados y reflexión final (1 punto)
#• Explica qué variables resultaron más influyentes en la predicción de la natalidad.
#Tal como se observó en el mapa de calor, la variable PIB per capita fue el predictor más fuerte, y su correlación negativa
#nos indica que a mayor PIB per capita, las tasas de natalidad son menores, lo que se podría explicar por la priorización del desarrollo
#personal y profesional.

#Además podemos observar influencia de variables como el acceso a servicios de salud y urbanización,
#el primero nos podría dar señales de mejores opciones de planificación familiar
#En cuanto a la urbanización, podría explicarse por el alto costo de la vida en zonas urbanas


#• Relaciona los resultados con tendencias demográficas globales.
#Están alineados con tendencias globales, paises con mayor PIB tienen tasas de natalidad menores que países menos desarrollados

#• Propón mejoras o ajustes para futuras versiones del modelo

#Añadir mas capas ocultas
#Añadir otras variables, como: tasa de fertilidad, datos socioeconomicos, políticas públicas
#(subsidios, acceso a anticonceptivos, políticas laborales)
#Y también será interesante agregar variables del contexto social de los países,
#por ejemplo, el movimiento 4B en Corea del Sur y su replicación en agrupaciones feministas en diversas partes del mundo.

#Modelo con parametros recomendados

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K

def create_model(learning_rate=0.1, neurons=32, dropout_rate=0.3):
    modelo = Sequential()

    # Capa de entrada
    modelo.add(Dense(units=neurons, activation='relu', input_dim=X_train_scaled.shape[1]))
    modelo.add(Dropout(dropout_rate))

    # Capa oculta
    modelo.add(Dense(units=neurons//2, activation='relu'))

    # Capa de salida
    modelo.add(Dense(units=1, activation='linear'))

    # optimizador Adam
    modelo.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])

    return modelo

# modelo con los parámetros óptimos
modelo_optimo = create_model(learning_rate=0.1, neurons=32, dropout_rate=0.3)

# entrenmiento del modelo
history_optimo = modelo_optimo.fit(X_train_scaled, y_train, epochs=100, batch_size=16, validation_split=0.2)

# Evaluacion deel modelo
loss, mae = modelo_optimo.evaluate(X_test_scaled, y_test)

# resultados
print(f"Pérdida en el conjunto de prueba: {loss}")
print(f"MAE en el conjunto de prueba: {mae}")

# Grafico de la evolución de la perdida
import matplotlib.pyplot as plt

plt.plot(history_optimo.history['loss'], label='Entrenamiento')
plt.plot(history_optimo.history['val_loss'], label='Validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

# Predicciones con el modelo entrenado
y_pred_optimo = modelo_optimo.predict(X_test_scaled)

# Grafico de las predicciones vs los valores reales
plt.scatter(y_test, y_pred_optimo)
plt.xlabel("Valores Reales de Tasa de Natalidad")
plt.ylabel("Predicciones de Tasa de Natalidad")
plt.title("Predicciones vs Realidad")
plt.show()

# Calculo del error absoluto medio (MAE)
error_optimo = np.abs(y_test - y_pred_optimo.flatten())
print(f"Error absoluto medio (MAE) con parámetros óptimos: {np.mean(error_optimo)}")