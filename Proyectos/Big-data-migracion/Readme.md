# üåç An√°lisis de Migraci√≥n Humana en el Siglo XXI con Apache Spark

Este proyecto es para estudiar tendencias de migraci√≥n humana en el siglo XXI. Usamos **Apache Spark y PySpark** para procesar un conjunto de datos sobre migraciones, sus causas y su impacto socioecon√≥mico en las regiones de origen y destino.

---

## üéØ Objetivos del proyecto

1. **Aplicar conceptos de Big Data** utilizando Apache Spark y PySpark.  
2. **Explorar y transformar** datos con RDDs y DataFrames.  
3. Realizar **consultas con Spark SQL** para identificar patrones migratorios.  
4. **Implementar modelos de aprendizaje autom√°tico con MLlib** para predecir flujos migratorios.

---

## üìÇ Dataset

El conjunto de datos incluye campos como:

- Pa√≠s de **Origen** y **Destino**  
- **Poblaci√≥n** involucrada en la migraci√≥n  
- **Raz√≥n** principal de migraci√≥n  
- Variables **socioecon√≥micas** de origen y destino (PIB, tasa de desempleo, nivel educativo, etc.)

---

## ‚öôÔ∏è Metodolog√≠a

### 1Ô∏è‚É£ Carga y exploraci√≥n de datos
- Crear una sesi√≥n Spark y cargar el CSV en un **DataFrame**.  
- Convertir los datos a **RDD** cuando sea necesario.  
- Inspeccionar el esquema, las primeras filas y estad√≠sticas descriptivas.

### 2Ô∏è‚É£ Procesamiento con RDDs y DataFrames
- Aplicar transformaciones con RDDs: `filter`, `map`, `flatMap`.  
- Realizar acciones con RDDs: `collect`, `take`, `count`.  
- Operaciones con DataFrames: filtrado, agregaci√≥n y ordenamiento.  
- Guardar resultados intermedios en **Parquet** para eficiencia y reproducibilidad.

### 3Ô∏è‚É£ Consultas con Spark SQL
- Registrar el DataFrame como tabla temporal.  
- Consultas para identificar principales pa√≠ses de origen/destino.  
- Agrupar por regi√≥n y analizar razones de migraci√≥n por regi√≥n.

### 4Ô∏è‚É£ Predicci√≥n con MLlib
- Preparar features con `VectorAssembler` y escalar con `StandardScaler`.  
- Construir un modelo de **Regresi√≥n Log√≠stica** (o alternativo) para predecir la probabilidad de migraci√≥n.  
- Evaluar con m√©tricas como **AUC** y **accuracy**; iterar sobre features y par√°metros.

---

## üìà Resultados principales (resumen)

- Identificaci√≥n de principales corredores migratorios y regiones con mayores flujos.  
- Determinaci√≥n de razones predominantes de migraci√≥n por regi√≥n (ej. econ√≥micas, conflicto, medio ambiente).  
- Modelo de clasificaci√≥n (regresi√≥n log√≠stica) con rendimiento evaluado mediante **AUC** y **accuracy**, √∫til como primera aproximaci√≥n para predecir probabilidad de migraci√≥n a partir de factores socioecon√≥micos.

---

## üîç Conclusiones y recomendaciones

- Spark permite procesar y transformar vol√∫menes grandes de datos de manera eficiente y pasar r√°pidamente a an√°lisis predictivo con MLlib.  
- Los resultados pueden informar pol√≠ticas p√∫blicas: focalizaci√≥n de intervenci√≥n en regiones vulnerables, pol√≠ticas de empleo y cooperaci√≥n internacional.  
- Recomendaciones:
  - Incluir series temporales para modelar tendencias a lo largo de a√±os.  
  - Probar modelos adicionales (Random Forest, GBT) y t√©cnicas de oversampling/undersampling si clases est√°n desbalanceadas.  
  - Integrar variables contextuales adicionales (conflictos, indicadores clim√°ticos) para mejorar el poder predictivo.

---

## üõ† Tecnolog√≠as utilizadas

- **Apache Spark / PySpark**  
- **Spark SQL**  
- **MLlib**  
- **Pandas** (para carga inicial y verificaci√≥n)  
- **Matplotlib / Seaborn** (visualizaciones auxiliares)

---

## üìÑ Archivos del repositorio (sugeridos)

- `migraciones.csv` ‚Äî dataset original  
- `analisis_migracion_spark.py` ‚Äî script principal con carga, transformaci√≥n y MLlib  
---

